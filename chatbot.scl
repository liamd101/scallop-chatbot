type questions(qid: i32, question: String)
type conversation(convo: String)


// ---------- parse documents ------------------
@pdf_reader
type $read_pdf(String) -> String

type document_paths(did: usize, path: String)
rel documents(did, $read_pdf(path)) = document_paths(did, path)

@chunk_document(
    chunk_size=100,
    chunk_overlap=20,
)
type doc_chunks(bound document: String, pid: usize, page: String)

rel pages(did, pid, page) = documents(did, document), doc_chunks(document, pid, page)


// ---------- embed documents -------------------
@gpt_encoder
type $embed_text(String) -> Tensor

rel equest(question, $embed_text(question)) = questions(qid, question)
rel epages(page, $embed_text(page)) = pages(did, pid, page)

rel doc_match(question, page) = equest(question, eques) and epages(page, edoc) and soft_eq<Tensor>(eques, edoc)

rel rel_docs(question, document) = document := top<3>(document: questions(qid, question), doc_match(question, document))
rel cc_rel_docs(q, docs) = docs := string_join<"\n">(d: rel_docs(q, d))


// --------- run chatbot -----
@gpt(
    header="""
    Use the following pieces of context to answer the question at the end. 
    If you don't know the answer, just say that you don't know, don't try to make up an answer. 
    If there are two or three likely answers, list all of the likely answers.
    Use three sentences maximum and keep the answer as concise as possible. 
    """
    prompt="""
    {{context}}
    Question: {{question}}
    Helpful Answer:
    {{response}}
    """,
    model="gpt-4",
    debug=false,
)
type chatbot(bound context: String, bound question: String, response: String)

rel responses(question, response) = questions(qid, question), cc_rel_docs(question, docs), conversation(c), chatbot(docs, question, response)

query cc_rel_docs
query responses
